{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Effective TensorFlow for Non-Experts (Google IO '17)](http://youtu.be/?v=5DknTFbcGVM)\n",
    "c:\\Users\\hcche\\Documents\\ML YouTube and Moocs\\Machine Learning\\Misc of ML and AI\\Inception slim models API\\Effective TensorFlow for Non-Experts (Google I_O '17)-5DknTFbcGVM.mp4                      \n",
    "# [Estimator demo using Automobile dataset](https://gist.github.com/martinwicke/6838c23abdc53e6bcda36ed9f40cff39)\n",
    "[Jupyter Notebook martinwicke/automobile.ipynb](https://goo.gl/0OgXiL)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[x] 2018.1.3 21:02 沒看懂這個 demo 是要幹嘛? --> 從訓練資料來觀察，看它的 features 跟 labels 就可以猜得出來 --> training_data = df[:160]; training_label = training_data.pop('price') 原來是要猜價錢，哈！see also the video @ 05:30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing to do: Download https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're using pandas to read the CSV file. This is easy for small datasets, but for large and complex datasets,\n",
    "# tensorflow parsing and processing functions are more powerful.\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CSV file does not have a header, so we have to fill in column names.\n",
    "names = [\n",
    "    'symboling', \n",
    "    'normalized-losses', \n",
    "    'make', \n",
    "    'fuel-type', \n",
    "    'aspiration',\n",
    "    'num-of-doors',\n",
    "    'body-style',\n",
    "    'drive-wheels',\n",
    "    'engine-location',\n",
    "    'wheel-base',\n",
    "    'length',\n",
    "    'width',\n",
    "    'height',\n",
    "    'curb-weight',\n",
    "    'engine-type',\n",
    "    'num-of-cylinders',\n",
    "    'engine-size',\n",
    "    'fuel-system',\n",
    "    'bore',\n",
    "    'stroke',\n",
    "    'compression-ratio',\n",
    "    'horsepower',\n",
    "    'peak-rpm',\n",
    "    'city-mpg',\n",
    "    'highway-mpg',\n",
    "    'price',\n",
    "]\n",
    "\n",
    "# We also have to specify dtypes.\n",
    "dtypes = {\n",
    "    'symboling': np.int32, \n",
    "    'normalized-losses': np.float32, \n",
    "    'make': str, \n",
    "    'fuel-type': str, \n",
    "    'aspiration': str,\n",
    "    'num-of-doors': str,\n",
    "    'body-style': str,\n",
    "    'drive-wheels': str,\n",
    "    'engine-location': str,\n",
    "    'wheel-base': np.float32,\n",
    "    'length': np.float32,\n",
    "    'width': np.float32,\n",
    "    'height': np.float32,\n",
    "    'curb-weight': np.float32,\n",
    "    'engine-type': str,\n",
    "    'num-of-cylinders': str,\n",
    "    'engine-size': np.float32,\n",
    "    'fuel-system': str,\n",
    "    'bore': np.float32,\n",
    "    'stroke': np.float32,\n",
    "    'compression-ratio': np.float32,\n",
    "    'horsepower': np.float32,\n",
    "    'peak-rpm': np.float32,\n",
    "    'city-mpg': np.float32,\n",
    "    'highway-mpg': np.float32,\n",
    "    'price': np.float32,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file.\n",
    "df = pd.read_csv('imports-85.data', names=names, dtype=dtypes, na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some rows don't have price data, we can't use those.\n",
    "df = df.dropna(axis='rows', how='any', subset=['price'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\\ 媽呀！下面這段 -- Pandas 太厲害了， df 竟然可以這樣操作。\n",
    "OK __main__ :> float_columns constant float_columns \n",
    "    // ( -- list ) df float_columns\n",
    "OK float_columns . cr\n",
    "['normalized-losses', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-size', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in continuous columns with zeros instead of NaN.\n",
    "float_columns = [k for k,v in dtypes.items() if v == np.float32]\n",
    "df[float_columns] = df[float_columns].fillna(value=0., axis='columns')\n",
    "# Fill missing values in continuous columns with '' instead of NaN (NaN mixed with strings is very bad for us).\n",
    "string_columns = [k for k,v in dtypes.items() if v == str]\n",
    "df[string_columns] = df[string_columns].fillna(value='', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set and an eval set.\n",
    "training_data = df[:160]\n",
    "eval_data = df[160:]\n",
    "\n",
    "# Separate input features from labels\n",
    "training_label = training_data.pop('price')\n",
    "eval_label = eval_data.pop('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please make sure that version >= 1.2:\n",
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "# Now we can start using some TensorFlow.\n",
    "import tensorflow as tf\n",
    "print('please make sure that version >= 1.2:')\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make input function for training: \n",
    "#   num_epochs=None -> will cycle through input data forever\n",
    "#   shuffle=True -> randomize order of input data\n",
    "training_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=training_data, y=training_label, \n",
    "    batch_size=64, shuffle=True, num_epochs=None)\n",
    "\n",
    "# Make input function for evaluation:\n",
    "#   shuffle=False -> do not randomize input data\n",
    "eval_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=eval_data, y=eval_label, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe how the model should interpret the inputs. \n",
    "# The names of the feature columns have to match the names\n",
    "# of the series in the dataframe.\n",
    "# [ ] 我們玩 WH300 就遇到了類似的問題， catagorical column 要\n",
    "先把 string 置換成數字才能餵給選定的 classifier, 但又怕數字的算數意義會不\n",
    "會被 classifier 誤會成某種特徵？以 make 為例，用 hash_bucket 就對了。\n",
    "我想看看泡製過的 make 是甚麼樣子？\n",
    "\n",
    "\n",
    "symboling = tf.feature_column.numeric_column('symboling')\n",
    "normalized_losses = tf.feature_column.numeric_column('normalized-losses')\n",
    "make = tf.feature_column.categorical_column_with_hash_bucket('make', 50)\n",
    "fuel_type = tf.feature_column.categorical_column_with_vocabulary_list('fuel-type', vocabulary_list=['diesel', 'gas'])\n",
    "aspiration = tf.feature_column.categorical_column_with_vocabulary_list('aspiration', vocabulary_list=['std', 'turbo'])\n",
    "num_of_doors = tf.feature_column.categorical_column_with_vocabulary_list('num-of-doors', vocabulary_list=['two', 'four'])\n",
    "body_style = tf.feature_column.categorical_column_with_vocabulary_list('body-style', vocabulary_list=['hardtop', 'wagon', 'sedan', 'hatchback', 'convertible'])\n",
    "drive_wheels = tf.feature_column.categorical_column_with_vocabulary_list('drive-wheels', vocabulary_list=['4wd', 'rwd', 'fwd'])\n",
    "engine_location = tf.feature_column.categorical_column_with_vocabulary_list('engine-location', vocabulary_list=['front', 'rear'])\n",
    "wheel_base = tf.feature_column.numeric_column('wheel-base')\n",
    "length = tf.feature_column.numeric_column('length')\n",
    "width = tf.feature_column.numeric_column('width')\n",
    "height = tf.feature_column.numeric_column('height')\n",
    "curb_weight = tf.feature_column.numeric_column('curb-weight')\n",
    "engine_type = tf.feature_column.categorical_column_with_vocabulary_list('engine-type', ['dohc', 'dohcv', 'l', 'ohc', 'ohcf', 'ohcv', 'rotor'])\n",
    "num_of_cylinders = tf.feature_column.categorical_column_with_vocabulary_list('num-of-cylinders', ['eight', 'five', 'four', 'six', 'three', 'twelve', 'two'])\n",
    "engine_size = tf.feature_column.numeric_column('engine-size')\n",
    "fuel_system = tf.feature_column.categorical_column_with_vocabulary_list('fuel-system', ['1bbl', '2bbl', '4bbl', 'idi', 'mfi', 'mpfi', 'spdi', 'spfi'])\n",
    "bore = tf.feature_column.numeric_column('bore')\n",
    "stroke = tf.feature_column.numeric_column('stroke')\n",
    "compression_ratio = tf.feature_column.numeric_column('compression-ratio')\n",
    "horsepower = tf.feature_column.numeric_column('horsepower')\n",
    "peak_rpm = tf.feature_column.numeric_column('peak-rpm')\n",
    "city_mpg = tf.feature_column.numeric_column('city-mpg')\n",
    "highway_mpg = tf.feature_column.numeric_column('highway-mpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_features = [symboling, normalized_losses, make, fuel_type, aspiration, num_of_doors,\n",
    "                   body_style, drive_wheels, engine_location, wheel_base, length, width,\n",
    "                   height, curb_weight, engine_type, num_of_cylinders, engine_size, fuel_system,\n",
    "                   bore, stroke, compression_ratio, horsepower, peak_rpm, city_mpg, highway_mpg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = tf.contrib.learn.LinearRegressor(feature_columns=linear_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\ 下面查出一堆 classifier, Estimator, Regressor 都不知怎麼區分的？ Stackoverflow 上有人問了也沒人回答 <br>\n",
    "\\ https://stackoverflow.com/questions/43401721/difference-between-dnnlinearcombinedestimator-regressor-classifier-tensorflo<br>\n",
    "\\ 還太新了？<br>\n",
    "\\__main\\__ :> tf.contrib.learn dir . cr \n",
    "\\['BaseEstimator', 'DNNClassifier', 'DNNEstimator', 'DNNLinearCombinedClassifier', 'DNNLinearCombinedEstimator', 'DNNLinearCombinedRegressor', __'DNNRegressor'__, 'DynamicRnnEstimator', 'Estimator', 'Evaluable', 'Experiment', 'ExportStrategy', 'Head', 'InputFnOps', 'KMeansClustering', 'LinearClassifier', 'LinearEstimator', __'LinearRegressor'__, 'LogisticRegressor', 'MetricSpec', 'ModeKeys', 'ModelFnOps', 'NanLossDuringTrainingError', 'NotFittedError', 'PredictionKey', 'ProblemType', 'RunConfig', 'SKCompat', 'SVM', 'TaskType', 'Trainable', ...snip ..., 'binary_svm_head', 'build_parsing_serving_input_fn', 'datasets', 'evaluate', 'extract_dask_data', 'extract_dask_labels', 'extract_pandas_data', 'extract_pandas_labels', 'extract_pandas_matrix', 'graph_actions', 'head', 'infer', 'infer_real_valued_columns_from_input', 'infer_real_valued_columns_from_input_fn', 'io', __'learn_runner'__, 'make_export_strategy', 'models', 'monitors', 'multi_class_head', 'multi_head', 'multi_label_head', 'no_op_train_fn', 'ops', 'poisson_regression_head', 'preprocessing', 'read_batch_examples', 'read_batch_features', 'read_batch_record_features', 'read_keyed_batch_examples', 'read_keyed_batch_examples_shared_queue', 'read_keyed_batch_features', 'read_keyed_batch_features_shared_queue', 'regression_head', 'run_feeds', 'run_n', 'train', 'utils']\n",
    "OK exit\n",
    "OK \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.fit(input_fn=training_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "接下來改用 DNNRegressor, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_features = [\n",
    "    #numerical features\n",
    "    symboling, normalized_losses, wheel_base, length, width, height, curb_weight, engine_size,\n",
    "    bore, stroke, compression_ratio, horsepower, peak_rpm, city_mpg, highway_mpg,    \n",
    "    # densify categorical features:\n",
    "    tf.feature_column.indicator_column(make),\n",
    "    tf.feature_column.indicator_column(fuel_type),\n",
    "    tf.feature_column.indicator_column(aspiration),\n",
    "    tf.feature_column.indicator_column(num_of_doors),\n",
    "    tf.feature_column.indicator_column(body_style),\n",
    "    tf.feature_column.indicator_column(drive_wheels), \n",
    "    tf.feature_column.indicator_column(engine_location),\n",
    "    tf.feature_column.indicator_column(engine_type),\n",
    "    tf.feature_column.indicator_column(num_of_cylinders),\n",
    "    tf.feature_column.indicator_column(fuel_system),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnregressor = tf.contrib.learn.DNNRegressor(feature_columns=dnn_features, hidden_units=[50, 30, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnregressor.fit(input_fn=training_input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnregressor.evaluate(input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_fn(run_config, params):\n",
    "  # This function makes an Experiment, containing an Estimator and inputs for training and evaluation.\n",
    "  # You can use params and config here to customize the Estimator depending on the cluster or to use\n",
    "  # hyperparameter tuning.\n",
    "\n",
    "  # Collect information for training\n",
    "  return tf.contrib.learn.Experiment(estimator=tf.contrib.learn.LinearRegressor(\n",
    "                                     feature_columns=linear_features, config=run_config),\n",
    "                                     train_input_fn=training_input_fn,\n",
    "                                     train_steps=10000,\n",
    "                                     eval_input_fn=eval_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil http://www.cnblogs.com/CLTANG/archive/2011/11/15/2249257.html\n",
    "import shutil\n",
    "shutil.rmtree(\"/tmp/output_dir\", ignore_errors=True)  # 刪除暫存目錄\n",
    "tf.contrib.learn.learn_runner.run(experiment_fn, run_config=tf.contrib.learn.RunConfig(model_dir=\"/tmp/output_dir\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "__main__ :> df constant df // ( -- dataframe ) \n",
    "__main__ :> pd constant pd // ( -- Pandas )\n",
    "\n",
    "df :> [:3] . cr\n",
    "   symboling  normalized-losses         make fuel-type aspiration  \\\n",
    "0          3                0.0  alfa-romero       gas        std   \n",
    "1          3                0.0  alfa-romero       gas        std   \n",
    "2          1                0.0  alfa-romero       gas        std   \n",
    "\n",
    "  num-of-doors   body-style drive-wheels engine-location  wheel-base   ...     \\\n",
    "0          two  convertible          rwd           front   88.599998   ...      \n",
    "1          two  convertible          rwd           front   88.599998   ...      \n",
    "2          two    hatchback          rwd           front   94.500000   ...      \n",
    "\n",
    "   engine-size  fuel-system  bore  stroke compression-ratio horsepower  \\\n",
    "0        130.0         mpfi  3.47    2.68               9.0      111.0   \n",
    "1        130.0         mpfi  3.47    2.68               9.0      111.0   \n",
    "2        152.0         mpfi  2.68    3.47               9.0      154.0   \n",
    "\n",
    "   peak-rpm city-mpg  highway-mpg    price  \n",
    "0    5000.0     21.0         27.0  13495.0  \n",
    "1    5000.0     21.0         27.0  16500.0  \n",
    "2    5000.0     19.0         26.0  16500.0  \n",
    "\n",
    "[3 rows x 26 columns]\n",
    "\n",
    "\\ Pandas 的 DataFrame 功能超多\n",
    "OK df dir . cr\n",
    "[...snip..., 'abs', 'add', 'add_prefix', 'add_suffix', 'agg', 'aggregate', 'align', 'all', 'any', 'append', 'apply', 'applymap', 'as_blocks', 'as_matrix', 'asfreq', 'asof', 'aspiration', 'assign', 'astype', 'at', 'at_time', 'axes', 'between_time', 'bfill', 'blocks', 'bool', 'bore', 'boxplot', 'clip', 'clip_lower', 'clip_upper', 'columns', 'combine', 'combine_first', 'compound', 'consolidate', 'convert_objects', 'copy', 'corr', 'corrwith', 'count', 'cov', 'cummax', 'cummin', 'cumprod', 'cumsum', 'describe', 'diff', 'div', 'divide', 'dot', 'drop', 'drop_duplicates', 'dropna', 'dtypes', 'duplicated', 'empty', 'eq', 'equals', 'eval', 'ewm', 'expanding', 'ffill', 'fillna', 'filter', 'first', 'first_valid_index', 'floordiv', 'from_csv', 'from_dict', 'from_items', 'from_records', 'ftypes', 'ge', 'get', 'get_dtype_counts', 'get_ftype_counts', 'get_value', 'get_values', 'groupby', 'gt', 'head', 'height', 'hist', 'horsepower', 'iat', 'idxmax', 'idxmin', 'iloc', 'index', 'info', 'insert', 'interpolate', 'is_copy', 'isin', 'isnull', 'items', 'iteritems', 'iterrows', 'itertuples', 'ix', 'join', 'keys', 'kurt', 'kurtosis', 'last', 'last_valid_index', 'le', 'length', 'loc', 'lookup', 'lt', 'mad', 'make', 'mask', 'max', 'mean', 'median', 'melt', 'memory_usage', 'merge', 'min', 'mod', 'mode', 'mul', 'multiply', 'ndim', 'ne', 'nlargest', 'notnull', 'nsmallest', 'nunique', 'pct_change', 'pipe', 'pivot', 'pivot_table', 'plot', 'pop', 'pow', 'price', 'prod', 'product', 'quantile', 'query', 'radd', 'rank', 'rdiv', 'reindex', 'reindex_axis', 'reindex_like', 'rename', 'rename_axis', 'reorder_levels', 'replace', 'resample', 'reset_index', 'rfloordiv', 'rmod', 'rmul', 'rolling', 'round', 'rpow', 'rsub', 'rtruediv', 'sample', 'select', 'select_dtypes', 'sem', 'set_axis', 'set_index', 'set_value', 'shape', 'shift', 'size', 'skew', 'slice_shift', 'sort_index', 'sort_values', 'sortlevel', 'squeeze', 'stack', 'std', 'stroke', 'style', 'sub', 'subtract', 'sum', 'swapaxes', 'swaplevel', 'symboling', 'tail', 'take', 'to_clipboard', 'to_csv', 'to_dense', 'to_dict', 'to_excel', 'to_feather', 'to_gbq', 'to_hdf', 'to_html', 'to_json', 'to_latex', 'to_msgpack', 'to_panel', 'to_period', 'to_pickle', 'to_records', 'to_sparse', 'to_sql', 'to_stata', 'to_string', 'to_timestamp', 'to_xarray', 'transform', 'transpose', 'truediv', 'truncate', 'tshift', 'tz_convert', 'tz_localize', 'unstack', 'update', 'values', 'var', 'where', 'width', 'xs']\n",
    "\\ 試著把 dataFrame 存放成 excel 用來觀察它\n",
    "OK df :> to_excel py: help(pop()) \\ 它要求 excel writer 搞不定\n",
    "OK df :> to_csv(\"imports-85.csv\") \\ csv 很簡單，一下就成功了。\n",
    "\n",
    "__main__ :> names constant names // ( -- list ) dataFrame column names\n",
    "__main__ :> dtypes constant dtypes // ( -- dict ) dataFrame column dtypes\n",
    "__main__ :> names . cr\n",
    "['symboling', 'normalized-losses', 'make', ..snip..., 'price']\n",
    "\n",
    "OK __main__ :> dtypes . cr\n",
    "{'symboling': <class 'numpy.int32'>, 'normalized-losses': <class 'numpy.float32'>, 'make': <class 'str'>, 'fuel-type': <class 'str'>, 'aspiration': <class 'str'>, 'num-of-doors': <class 'str'>, 'body-style': <class 'str'>, 'drive-wheels': <class 'str'>, 'engine-location': <class 'str'>, 'wheel-base': <class 'numpy.float32'>, 'length': <class 'numpy.float32'>, 'width': <class 'numpy.float32'>, 'height': <class 'numpy.float32'>, 'curb-weight': <class 'numpy.float32'>, 'engine-type': <class 'str'>, 'num-of-cylinders': <class 'str'>, 'engine-size': <class 'numpy.float32'>, 'fuel-system': <class 'str'>, 'bore': <class 'numpy.float32'>, 'stroke': <class 'numpy.float32'>, 'compression-ratio': <class 'numpy.float32'>, 'horsepower': <class 'numpy.float32'>, 'peak-rpm': <class 'numpy.float32'>, 'city-mpg': <class 'numpy.float32'>, 'highway-mpg': <class 'numpy.float32'>, 'price': <class 'numpy.float32'>}\n",
    "\n",
    "# Fill missing values in continuous columns with zeros instead of NaN.\n",
    "float_columns = [k for k,v in dtypes.items() if v == np.float32]\n",
    "df[float_columns] = df[float_columns].fillna(value=0., axis='columns')\n",
    "\n",
    "# Fill missing values in continuous columns with '' instead of NaN (NaN mixed with strings is very bad for us).\n",
    "string_columns = [k for k,v in dtypes.items() if v == str]\n",
    "df[string_columns] = df[string_columns].fillna(value='', axis='columns')\n",
    "\n",
    "OK __main__ :> float_columns constant float_columns \n",
    "    // ( -- list ) df float_columns\n",
    "OK float_columns . cr\n",
    "['normalized-losses', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-size', 'bore', 'stroke', 'compression-ratio', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
    "OK \n",
    "\n",
    "__main__ :> dnnregressor constant dnnregressor // ( -- obj ) \n",
    "OK dnnregressor . cr\n",
    "DNNRegressor(params={'head': <tensorflow.contrib.learn.python.learn.estimators.head._RegressionHead object at 0x000001E7E70A1748>, 'hidden_units': [50, 30, 10], 'feature_columns': (_NumericColum ... snip .... \n",
    "\n",
    "dnnregressor dir . cr\n",
    "['_Config', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__metaclass__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_call_model_fn', '_check_inputs', '_config', '_device_fn', '_evaluate_model', '_extract_metric_update_ops', '_feature_columns', '_feature_engineering_fn', '_features_info', '_filter_predictions', '_get_eval_ops', '_get_feature_ops_from_example', '_get_features_from_input_fn', '_get_predict_ops', '_get_train_ops', '_graph', '_infer_model', '_is_input_constant', '_labels_info', '_model_dir', '_model_fn', '_predict_generator', '_session_config', '_train_model', 'config', 'evaluate', 'export', 'export_savedmodel', 'fit', 'get_params', 'get_variable_names', 'get_variable_value', 'model_dir', 'params', 'partial_fit', 'predict', 'predict_scores', 'set_params']\n",
    "OK \n",
    "\n",
    "\\ 抓出一筆 feature \n",
    "OK eval_data :> [10:11] . cr\n",
    "     symboling  normalized-losses    make fuel-type aspiration num-of-doors  \\\n",
    "174         -1               65.0  toyota    diesel      turbo         four   \n",
    "\n",
    "    body-style drive-wheels engine-location  wheel-base     ...       \\\n",
    "174      sedan          fwd           front  102.400002     ...        \n",
    "\n",
    "     num-of-cylinders  engine-size  fuel-system  bore stroke  \\\n",
    "174              four        110.0          idi  3.27   3.35   \n",
    "\n",
    "    compression-ratio  horsepower peak-rpm  city-mpg  highway-mpg  \n",
    "174              22.5        73.0   4500.0      30.0         33.0  \n",
    "\n",
    "[1 rows x 25 columns]\n",
    "OK \n",
    "dnnregressor :> predict(v('eval_data')[0:1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "peforth.ok()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = dnnregressor.predict(x=dict(eval_data[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i for i in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = dnnregressor.predict(x=dict(eval_data[20:21]))\n",
    "print(eval_data[20:21])\n",
    "[i for i in _]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = dnnregressor.predict(x=dict(eval_data[27:28]))\n",
    "print(eval_data[27:28])\n",
    "[i for i in _]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[k for k,v in dtypes if v == np.float32]\n",
    "mydict = {'aa':11,'bb':22}\n",
    "[i for i in mydict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[mydict[i] for i in mydict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(n,k) for k,n in mydict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = tf.contrib.learn.LinearRegressor(feature_columns=linear_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_HashedCategoricalColumn(key='make', hash_bucket_size=50, dtype=tf.string)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IdWeightPair',\n",
       " '__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__metaclass__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_asdict',\n",
       " '_fields',\n",
       " '_get_sparse_tensors',\n",
       " '_make',\n",
       " '_num_buckets',\n",
       " '_parse_example_spec',\n",
       " '_replace',\n",
       " '_source',\n",
       " '_transform_feature',\n",
       " 'count',\n",
       " 'dtype',\n",
       " 'hash_bucket_size',\n",
       " 'index',\n",
       " 'key',\n",
       " 'name']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(make)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make._num_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      alfa-romero\n",
       "1      alfa-romero\n",
       "2      alfa-romero\n",
       "3             audi\n",
       "4             audi\n",
       "5             audi\n",
       "6             audi\n",
       "7             audi\n",
       "8             audi\n",
       "10             bmw\n",
       "11             bmw\n",
       "12             bmw\n",
       "13             bmw\n",
       "14             bmw\n",
       "15             bmw\n",
       "16             bmw\n",
       "17             bmw\n",
       "18       chevrolet\n",
       "19       chevrolet\n",
       "20       chevrolet\n",
       "21           dodge\n",
       "22           dodge\n",
       "23           dodge\n",
       "24           dodge\n",
       "25           dodge\n",
       "26           dodge\n",
       "27           dodge\n",
       "28           dodge\n",
       "29           dodge\n",
       "30           honda\n",
       "          ...     \n",
       "175         toyota\n",
       "176         toyota\n",
       "177         toyota\n",
       "178         toyota\n",
       "179         toyota\n",
       "180         toyota\n",
       "181         toyota\n",
       "182     volkswagen\n",
       "183     volkswagen\n",
       "184     volkswagen\n",
       "185     volkswagen\n",
       "186     volkswagen\n",
       "187     volkswagen\n",
       "188     volkswagen\n",
       "189     volkswagen\n",
       "190     volkswagen\n",
       "191     volkswagen\n",
       "192     volkswagen\n",
       "193     volkswagen\n",
       "194          volvo\n",
       "195          volvo\n",
       "196          volvo\n",
       "197          volvo\n",
       "198          volvo\n",
       "199          volvo\n",
       "200          volvo\n",
       "201          volvo\n",
       "202          volvo\n",
       "203          volvo\n",
       "204          volvo\n",
       "Name: make, Length: 201, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['make']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
